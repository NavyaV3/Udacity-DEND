# Project 1 : Data Modeling with Postgres

## Overview

A startup called Sparkify wants to analyze the data they've been collecting on songs and user activity on their new music streaming app. The data collected is stored in JSON files and the analytics team is interested in understanding what songs users are listening to. 

The goal of this project is to create a Postgres database schema and ETL pipeline to optimize queries for song play analysis.

## Datasets

There are two datasets as part of this project.

### 1. Song dataset
Song dataset is a subset of real data from the [Million Song Datase](https://labrosa.ee.columbia.edu/millionsong/).

Sample data:
```
{
"num_songs": 1, 
"artist_id": "ARJIE2Y1187B994AB7", 
"artist_latitude": null, 
"artist_longitude": null, 
"artist_location": "", 
"artist_name": "Line Renaud", 
"song_id": "SOUPIRU12A6D4FA1E1", 
"title": "Der Kleine Dompfaff", 
"duration": 152.92036, 
"year": 0
}
```

### 2. Log dataset
Log dataset consists of log files generated by [event simulator](https://github.com/Interana/eventsim) based on the songs in the song dataset.

Sample data:
```
{
"artist": "Survivor", 
"auth": "Logged In", 
"firstName": "Jayden", 
"gender": "M", 
"itemInSession": 0, 
"lastName": "Fox", 
"length": 245.36771, 
"level": "free", 
"location": "New Orleans-Metairie, LA", 
"method": "PUT",
"page": "NextSong", 
"registration": 1541033612796, 
"sessionId": 100, 
"song": "Eye Of The Tiger", 
"status": 200, 
"ts": 1541110994796, 
"userAgent": "\"Mozilla/5.0 (Windows NT 6.3; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/36.0.1985.143 Safari/537.36\"", 
"userId": "101"
}
```
## Schema
A star schema optimized for queries on song play analysis is created by using the below tables.
### Fact tables
**songplays** : Records in log data associated with song plays i.e. records with page `NextSong`
> songplay_id, start_time, user_id, level, song_id, artist_id, session_id, location, user_agent

### Dimension tables
**users** : users in the app
> user_id, first_name, last_name, gender, level

**songs** : songs in music database
> song_id, title, artist_id, year, duration

**artists** : artists in music database
> artist_id, name, location, latitude, longitude

**time** : timestamps of records in songplays broken down into specific units
> start_time, hour, day, week, month, year, weekday

## Python Files

`sql_queries.py` : contains sql queries for dropping and creating fact and dimension tables as well as insertion query templates.

`create_tables.py` : drops and creates ***sparkify*** database. This file is run before each ETL script run to reset the tables.

`etl.ipynb` : reads and processes a single file from song_data and log_data and loads the data into the tables.

`etl.py` : reads and processes files from song_data and log_data and loads them into the tables. 

`test.ipynb` : displays the first few rows of each table to validate the loaded data.

## Execution Instructions

1. Run `create_tables.py` in the terminal to create the database and table structure
2. Run `etl.py` to extract and load the data to the tables.
3. Execute the queries in `test.ipynb` to validate the loaded data.



